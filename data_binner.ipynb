{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile boundaries: p20=0.034876, p40=0.066469, p60=0.105164, p80=0.164659\n",
      "Updated files saved with 'engagement_score' and 'engagement_label' fields\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load your JSON data\n",
    "with open('../data/train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('../data/test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "with open('../data/validation.json', 'r', encoding='utf-8') as f:\n",
    "    validation_data = json.load(f)\n",
    "\n",
    "# Combine to calculate global quantiles\n",
    "all_data = train_data + test_data + validation_data\n",
    "\n",
    "# Calculate engagement scores for all items\n",
    "engagement_scores = []\n",
    "for item in all_data:\n",
    "    eng = item['engagement']\n",
    "    # Your formula: (1×likes + 2×comments + 3×shares) / views\n",
    "    score = (1 * eng['likes'] + 2 * eng['comments'] + 3 * eng['shares'] + 3 * eng['favorites']) / max(eng['views'], 1)\n",
    "    engagement_scores.append(score)\n",
    "\n",
    "# Calculate global quantile boundaries\n",
    "p20, p40, p60, p80 = np.percentile(engagement_scores, [20, 40, 60, 80])\n",
    "\n",
    "# Function to add scores and labels to a dataset\n",
    "def add_engagement_info(data):\n",
    "    for item in data:\n",
    "        eng = item['engagement']\n",
    "        \n",
    "        # Calculate engagement score\n",
    "        score = (1 * eng['likes'] + 2 * eng['comments'] + 3 * eng['shares']) / max(eng['views'], 1)\n",
    "        item['engagement_score'] = float(score)\n",
    "        \n",
    "        # Assign label based on global quantiles\n",
    "        if score <= p20:\n",
    "            item['engagement_label'] = \"Very Low\"\n",
    "        elif score <= p40:\n",
    "            item['engagement_label'] = \"Low\"\n",
    "        elif score <= p60:\n",
    "            item['engagement_label'] = \"Average\"\n",
    "        elif score <= p80:\n",
    "            item['engagement_label'] = \"High\"\n",
    "        else:\n",
    "            item['engagement_label'] = \"Very High\"\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Add to all datasets\n",
    "train_data = add_engagement_info(train_data)\n",
    "test_data = add_engagement_info(test_data)\n",
    "validation_data = add_engagement_info(validation_data)\n",
    "\n",
    "# Save updated JSON files\n",
    "with open('../data/train_with_eng.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, indent=2, ensure_ascii=False)\n",
    "with open('../data/test_with_eng.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_data, f, indent=2, ensure_ascii=False)\n",
    "with open('../data/validation_with_eng.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(validation_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Quantile boundaries: p20={p20:.6f}, p40={p40:.6f}, p60={p60:.6f}, p80={p80:.6f}\")\n",
    "print(f\"Updated files saved with 'engagement_score' and 'engagement_label' fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': '../cover/i29115.jpg',\n",
       " 'title': \"This...is it even a guy? Ten Thousand Pink Women's Clothing!\",\n",
       " 'tag': 'Daily Life',\n",
       " 'description': \"This trip down is really too tired, spent a lot of time on the road, and most of the day in various poses, really sore back... If you think it looks good, or if you think I'm really serious about it, I hope you'll long press the like button to give me a three-peat~!\",\n",
       " 'engagement_label': 'High'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: value for key, value in train_data[0].items() if key not in ['engagement_score', 'engagement']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
